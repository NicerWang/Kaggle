{"metadata":{"colab":{"provenance":[],"collapsed_sections":["RJtKN6ANUADM"],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"accelerator":"GPU","language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# GFPGAN Inference Demo ","metadata":{"id":"RJtKN6ANUADM"}},{"cell_type":"markdown","source":"# 1. Preparations\n","metadata":{"id":"ZY1Zbo3uUkXg"}},{"cell_type":"code","source":"# Clone GFPGAN and enter the GFPGAN folder\n# !rm -rf GFPGAN\n!git clone https://github.com/TencentARC/GFPGAN.git\n%cd GFPGAN\n\n# Set up the environment\n# Install basicsr - https://github.com/xinntao/BasicSR\n# We use BasicSR for both training and inference\n!pip install basicsr\n# Install facexlib - https://github.com/xinntao/facexlib\n# We use face detection and face restoration helper in the facexlib package\n!pip install facexlib\n# Install other depencencies\n!pip install -r requirements.txt\n!python setup.py develop\n!pip install realesrgan  # used for enhancing the background (non-face) regions","metadata":{"id":"ZwH2ifWEYEfJ","colab":{"base_uri":"https://localhost:8080/"},"outputId":"33875f5a-cd69-4efa-8703-011f573cb9de","_kg_hide-input":false,"_kg_hide-output":false,"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. Inference","metadata":{"id":"lGHc73Up70ZA"}},{"cell_type":"code","source":"# Now we use the GFPGAN to restore the above low-quality images\n# We use [Real-ESRGAN](https://github.com/xinntao/Real-ESRGAN) for enhancing the background (non-face) regions\n# You can find the different models in https://github.com/TencentARC/GFPGAN#european_castle-model-zoo\n!python inference_gfpgan.py -i ../../input/upload -o /kaggle/working/output -v 1.4 -s 2\n\n# Usage: python inference_gfpgan.py -i inputs/whole_imgs -o results -v 1.3 -s 2 [options]...\n# \n#  -h                   show this help\n#  -i input             Input image or folder. Default: inputs/whole_imgs\n#  -o output            Output folder. Default: results\n#  -v version           GFPGAN model version. Option: 1 | 1.2 | 1.3. Default: 1.3\n#  -s upscale           The final upsampling scale of the image. Default: 2\n#  -bg_upsampler        background upsampler. Default: realesrgan\n#  -bg_tile             Tile size for background sampler, 0 for no tile during testing. Default: 400\n#  -suffix              Suffix of the restored faces\n#  -only_center_face    Only restore the center face\n#  -aligned             Input are aligned faces\n#  -ext                 Image extension. Options: auto | jpg | png, auto means using the same extension as inputs. Default: auto","metadata":{"id":"lmQVC3s97z4z","colab":{"base_uri":"https://localhost:8080/"},"outputId":"68446bf2-bc9a-46d2-ce4a-41ed6d70be2e","scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. Download results","metadata":{"id":"HR7VEBEb8slX"}},{"cell_type":"code","source":"%cd /kaggle/working/\nfrom pathlib import Path\nimport zipfile\nimg_root = Path('/kaggle/working/output/restored_imgs')\nwith zipfile.ZipFile('imgs.zip', 'w') as z:\n    for img_name in img_root.iterdir():\n        z.write(img_name)\nfrom IPython.display import FileLink\nFileLink('imgs.zip')","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"id":"zuBCgeH08tdn","outputId":"59c7c9d8-b601-4378-99ae-079d5b7ab85b","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4.Clean Previous Result For Re-Inference","metadata":{}},{"cell_type":"code","source":"!rm -rf /kaggle/working/output\n!rm -rf imgs.zip\n%cd GFPGAN","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}